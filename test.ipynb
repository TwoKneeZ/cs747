{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import pandas as pd\n","import os\n","from PIL import Image, ImageOps\n","from torchvision import transforms\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchvision import models\n","import torch.optim as optim\n","from sklearn.metrics import cohen_kappa_score\n","from sklearn.model_selection import train_test_split\n","from scripts.model import DRDetection\n","from scripts.loss import FocalLoss\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["script_name = os.path.splitext(os.path.basename(__file__))[0]"]},{"cell_type":"markdown","metadata":{},"source":["In[2]:"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["MEAN = [0.41661593, 0.29097975, 0.20843531]\n","STD = [0.26398131, 0.19219237, 0.15810781]"]},{"cell_type":"markdown","metadata":{},"source":["# Custom class for dataset loading"]},{"cell_type":"markdown","metadata":{},"source":["In[3]:"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class CustomImageDataset(Dataset):\n","    def __init__(self, file_paths, labels=None, transform=None):\n","        self.file_paths = file_paths\n","        self.labels = labels\n","        self.transform = transform\n","        # self.inverted = inverted  # New column for inversion status\n","    def __len__(self):\n","        return len(self.file_paths)\n","    def __getitem__(self, idx):\n","        img_path = self.file_paths[idx]\n","        image = Image.open(img_path + '.jpeg').convert(\"RGB\")\n","        \n","        # # Check and handle inversion\n","        # if self.inverted is not None and self.inverted[idx] == 1:\n","        #     image = ImageOps.flip(image)  # Un-invert the image\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.labels is not None:  # For training and validation\n","            label = self.labels[idx]\n","            return image, label\n","        else:  # For testing\n","            return image"]},{"cell_type":"markdown","metadata":{},"source":["In[4]:"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["train_transform = transforms.Compose([\n","            # transforms.Resize((380, 380)),\n","            # transforms.RandomHorizontalFlip(p=0.5),                    # Random horizontal flip\n","            # transforms.ColorJitter(brightness=0.2, contrast=0.2),      # Random brightness/contrast\n","            transforms.ToTensor(),                                    # Convert to Tensor\n","            transforms.Normalize(mean=MEAN,         \n","                                 std=STD),\n","        ])"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["val_test_transform = transforms.Compose([\n","            # transforms.Resize((380, 380)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=MEAN,\n","                                 std=STD),\n","        ])"]},{"cell_type":"markdown","metadata":{},"source":["In[5]:"]},{"cell_type":"markdown","metadata":{},"source":["Load CSV"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["csv_path = \"trainLabels.csv\"\n","data = pd.read_csv(csv_path)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["class_weights = dict(len(data)/data['level'].value_counts())\n","class_weights = torch.tensor([class_weights[i] for i in sorted(class_weights.keys())], dtype=torch.float)"]},{"cell_type":"markdown","metadata":{},"source":["Add full paths to image files"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["train_folder = \"train_prep512/\"\n","data['image_path'] = data['image'].apply(lambda x: os.path.join(train_folder, x))"]},{"cell_type":"markdown","metadata":{},"source":["inverted = data['inverted'].values"]},{"cell_type":"markdown","metadata":{},"source":["Stratified split for training and validation"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["train_paths, val_paths, train_labels, val_labels = train_test_split(\n","    data['image_path'].values,\n","    data['level'].values,\n","    # inverted,\n","    test_size=0.1,  # 10% for validation\n","    stratify=data['level'].values,\n","    random_state=42\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Loading the dataset"]},{"cell_type":"markdown","metadata":{},"source":["In[6]:"]},{"cell_type":"markdown","metadata":{},"source":["Training and Validation datasets"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["train_dataset = CustomImageDataset(train_paths, train_labels, transform=train_transform)\n","val_dataset = CustomImageDataset(val_paths, val_labels, transform=val_test_transform)"]},{"cell_type":"markdown","metadata":{},"source":["Data loaders"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"]},{"cell_type":"markdown","metadata":{},"source":["# Model building"]},{"cell_type":"markdown","metadata":{},"source":["In[15]:"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def train_model_with_validation(device, model, train_loader, val_loader, optimizer, criterion, scheduler=None, num_epochs=10):\n","    model.train()\n","    training_loss, validation_loss = [], []\n","    training_acc, validation_acc = [], []\n","    kappa_score = []\n","    for epoch in range(num_epochs):\n","        # Training phase\n","        running_loss = 0.0\n","        correct = 0\n","        total = 0\n","        for images, labels in tqdm(train_loader):\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(images) #inceptionv3 returns two outputs\n","            loss = criterion(outputs, labels)\n","\n","            # Backward pass and optimization\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","        train_accuracy = 100 * correct / total\n","        train_loss = running_loss / len(train_loader)\n","\n","        # Validation phase\n","        model.eval()\n","        val_loss = 0.0\n","        val_correct = 0\n","        val_total = 0\n","        y_true = []\n","        y_pred = []\n","        with torch.no_grad():\n","            for images, labels in tqdm(val_loader):\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","                _, predicted = torch.max(outputs, 1)\n","                val_total += labels.size(0)\n","                val_correct += (predicted == labels).sum().item()\n","                # Collect predictions and true labels for Kappa calculation\n","                y_true.extend(labels.cpu().numpy())\n","                y_pred.extend(predicted.cpu().numpy())\n","        val_accuracy = 100 * val_correct / val_total\n","        val_loss /= len(val_loader)\n","\n","        # Quadratic Weighted Kappa Score\n","        kappa = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n","        training_loss.append(train_loss)\n","        validation_loss.append(val_loss)\n","        training_acc.append(train_accuracy)\n","        validation_acc.append(val_accuracy)\n","        kappa_score.append(kappa)\n","        if scheduler:\n","            scheduler.step()\n","\n","        # Print epoch metrics\n","        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n","        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n","        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, Kappa Score: {kappa:.4f}\\n\")\n","        model.train()  # Switch back to training mode\n","        \n","    return training_loss, validation_loss, training_acc, validation_acc, kappa_score"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def init_model():\n","    # model = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.DEFAULT)\n","    # num_features = model.classifier[1].in_features\n","    # model.classifier[1] = nn.Linear(num_features, 5)\n","    model = DRDetection(dropout_prob=0.5, leakiness=0.05)\n","    \n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["In[18]:"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = init_model().to(device)"]},{"cell_type":"markdown","metadata":{},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))  # You can pass class weights here if needed"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# criterion = FocalLoss(gamma=3).to(device)\n","criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n","# optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n","optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-4, nesterov=True)\n","# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","scheduler = None"]},{"cell_type":"markdown","metadata":{},"source":["In[19]:"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 988/988 [01:54<00:00,  8.64it/s]\n","100%|██████████| 110/110 [00:07<00:00, 14.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/10]\n","Train Loss: 38.8544, Train Accuracy: 22.09%\n","Val Loss: 3.7702, Val Accuracy: 14.80%, Kappa Score: 0.0020\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 988/988 [01:53<00:00,  8.67it/s]\n","100%|██████████| 110/110 [00:06<00:00, 15.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/10]\n","Train Loss: 3.2894, Train Accuracy: 22.99%\n","Val Loss: 1.7741, Val Accuracy: 3.16%, Kappa Score: 0.0009\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 988/988 [01:52<00:00,  8.78it/s]\n","100%|██████████| 110/110 [00:07<00:00, 14.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/10]\n","Train Loss: 2.1993, Train Accuracy: 25.49%\n","Val Loss: 1.8088, Val Accuracy: 58.90%, Kappa Score: 0.0178\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 988/988 [01:55<00:00,  8.52it/s]\n","100%|██████████| 110/110 [00:07<00:00, 15.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/10]\n","Train Loss: 1.8605, Train Accuracy: 26.60%\n","Val Loss: 1.6916, Val Accuracy: 17.93%, Kappa Score: 0.0055\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 988/988 [01:53<00:00,  8.70it/s]\n","100%|██████████| 110/110 [00:07<00:00, 14.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/10]\n","Train Loss: 1.7944, Train Accuracy: 28.12%\n","Val Loss: 1.6759, Val Accuracy: 15.49%, Kappa Score: -0.0034\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 988/988 [01:54<00:00,  8.61it/s]\n","100%|██████████| 110/110 [00:07<00:00, 15.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [6/10]\n","Train Loss: 1.7207, Train Accuracy: 32.93%\n","Val Loss: 1.6429, Val Accuracy: 6.97%, Kappa Score: 0.0000\n","\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 25/988 [00:04<03:02,  5.28it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/scratch/skodukul/747_project/test.ipynb Cell 35\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ondemand.orc.gmu.edu/scratch/skodukul/747_project/test.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ondemand.orc.gmu.edu/scratch/skodukul/747_project/test.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m training_loss, validation_loss, training_acc, validation_acc, kappa_score \u001b[39m=\u001b[39m train_model_with_validation(device, model, train_loader, val_loader, optimizer, criterion, scheduler, epochs)\n\u001b[1;32m      <a href='vscode-notebook-cell://ondemand.orc.gmu.edu/scratch/skodukul/747_project/test.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel/\u001b[39m\u001b[39m{\u001b[39;00mscript_name\u001b[39m}\u001b[39;00m\u001b[39m_model.pth\u001b[39m\u001b[39m\"\u001b[39m)\n","\u001b[1;32m/scratch/skodukul/747_project/test.ipynb Cell 35\u001b[0m line \u001b[0;36mtrain_model_with_validation\u001b[0;34m(device, model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ondemand.orc.gmu.edu/scratch/skodukul/747_project/test.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ondemand.orc.gmu.edu/scratch/skodukul/747_project/test.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ondemand.orc.gmu.edu/scratch/skodukul/747_project/test.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ondemand.orc.gmu.edu/scratch/skodukul/747_project/test.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ondemand.orc.gmu.edu/scratch/skodukul/747_project/test.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["epochs=10\n","training_loss, validation_loss, training_acc, validation_acc, kappa_score = train_model_with_validation(device, model, train_loader, val_loader, optimizer, criterion, scheduler, epochs)\n","torch.save(model.state_dict(), f\"model/{script_name}_model.pth\")"]},{"cell_type":"markdown","metadata":{},"source":["In[21]:"]},{"cell_type":"markdown","metadata":{},"source":["Plot Loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(12, 6))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n","plt.plot(training_loss, label='Training Loss', marker='o')\n","plt.plot(validation_loss, label='Validation Loss', marker='o')\n","plt.title('Loss over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid()"]},{"cell_type":"markdown","metadata":{},"source":["Plot Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n","plt.plot(training_acc, label='Training Accuracy', marker='o')\n","plt.plot(validation_acc, label='Validation Accuracy', marker='o')\n","plt.title('Accuracy over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.grid()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.tight_layout()\n","plt.savefig(f'images/{script_name}_test_val.png')"]},{"cell_type":"markdown","metadata":{},"source":["Plot Kappa Score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(6, 4))\n","plt.plot(kappa_score, label='Kappa Score', marker='o', color='purple')\n","plt.title('Kappa Score over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Kappa Score')\n","plt.legend()\n","plt.grid()\n","plt.savefig(f'images/{script_name}_kappa.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_folder = \"test_prep512/\"\n","test_files = os.listdir(test_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for f in test_files:\n","    img = Image.open(os.path.join(test_folder, f)).convert('RGB')\n","    with torch.no_grad():\n","        outputs = model(val_test_transform(img).unsqueeze(0).to(device))\n","        _, pred = torch.max(outputs, 1)  # Get the class index with the highest score\n","        results.append([os.path.splitext(f)[0], pred.item()])"]},{"cell_type":"markdown","metadata":{},"source":["Save to a single CSV"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.DataFrame(results, columns=[\"image\", \"level\"])\n","df.to_csv(f\"output/{script_name}_predictions.csv\", index=False)\n","print(\"Predictions saved\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":2}
